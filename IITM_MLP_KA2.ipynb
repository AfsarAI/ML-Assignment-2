{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 107399,
          "databundleVersionId": 13009703,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 31089,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "IITM_MLP_KA2",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AfsarAI/ML-Assignment-2/blob/main/IITM_MLP_KA2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "tR8vLfmboy5Y"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "mlp_term_2_2025_kaggle_assignment_2_path = kagglehub.competition_download('mlp-term-2-2025-kaggle-assignment-2')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "tLs-YxbXoy5d"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-23T16:29:35.251562Z",
          "iopub.execute_input": "2025-07-23T16:29:35.251848Z",
          "iopub.status.idle": "2025-07-23T16:29:35.59106Z",
          "shell.execute_reply.started": "2025-07-23T16:29:35.251826Z",
          "shell.execute_reply": "2025-07-23T16:29:35.590241Z"
        },
        "id": "whO1RAD4oy5f"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the data\n"
      ],
      "metadata": {
        "id": "LNpKWM1Boy5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('/kaggle/input/mlp-term-2-2025-kaggle-assignment-2/train.csv')\n",
        "test_df = pd.read_csv('/kaggle/input/mlp-term-2-2025-kaggle-assignment-2/test.csv')\n",
        "\n",
        "train_df.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-23T16:29:35.592816Z",
          "iopub.execute_input": "2025-07-23T16:29:35.593208Z",
          "iopub.status.idle": "2025-07-23T16:29:35.959821Z",
          "shell.execute_reply.started": "2025-07-23T16:29:35.593184Z",
          "shell.execute_reply": "2025-07-23T16:29:35.958983Z"
        },
        "id": "B643n8fmoy5i"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Criteria 1\n",
        "## Identify data types of different columns"
      ],
      "metadata": {
        "id": "4aINytb-oy5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.dtypes"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-23T16:29:35.960658Z",
          "iopub.execute_input": "2025-07-23T16:29:35.960949Z",
          "iopub.status.idle": "2025-07-23T16:29:35.96779Z",
          "shell.execute_reply.started": "2025-07-23T16:29:35.960927Z",
          "shell.execute_reply": "2025-07-23T16:29:35.967078Z"
        },
        "id": "WT4yxO1woy5k"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Criteria 2\n",
        "## Present descriptive statistics of numerical columns"
      ],
      "metadata": {
        "id": "pOk1fda-oy5l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.describe().T"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-23T16:29:35.96864Z",
          "iopub.execute_input": "2025-07-23T16:29:35.969105Z",
          "iopub.status.idle": "2025-07-23T16:29:36.075265Z",
          "shell.execute_reply.started": "2025-07-23T16:29:35.969072Z",
          "shell.execute_reply": "2025-07-23T16:29:36.074471Z"
        },
        "id": "A4WsvEiooy5l"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Criteria 3\n",
        "## Identify and handle the missing values"
      ],
      "metadata": {
        "id": "_kFSpP-goy5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.isnull().sum()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-23T16:29:36.078163Z",
          "iopub.execute_input": "2025-07-23T16:29:36.07857Z",
          "iopub.status.idle": "2025-07-23T16:29:36.116428Z",
          "shell.execute_reply.started": "2025-07-23T16:29:36.078538Z",
          "shell.execute_reply": "2025-07-23T16:29:36.115559Z"
        },
        "id": "cSBDASO1oy5m"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.isnull().sum()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-23T16:29:36.117421Z",
          "iopub.execute_input": "2025-07-23T16:29:36.117732Z",
          "iopub.status.idle": "2025-07-23T16:29:36.132426Z",
          "shell.execute_reply.started": "2025-07-23T16:29:36.117703Z",
          "shell.execute_reply": "2025-07-23T16:29:36.13155Z"
        },
        "id": "hdCMG4ngoy5n"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# We will impute missing values\n",
        "* credit_score:- 9556 & 3185 null values in train and test df respectively, will impute using median as it is more robust to outliers.\n",
        "* country:- 6021 & 4606 null values in train and test df respectively, will impute using mode because it is a categorical feature.\n",
        "* acc_balance:- 7257 & 5251 null values in train and test df respectively, will impute using median.\n",
        "* prod_count:- 4863 & 1717 null values in train and test df respectively, will impute using median"
      ],
      "metadata": {
        "id": "L5wjLEJMoy5n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "mean_col=['credit_score', 'acc_balance','prod_count']\n",
        "mode_col=['country']\n",
        "\n",
        "mean_imputer=SimpleImputer(strategy='mean')\n",
        "mode_imputer=SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "train_df[mean_col]=mean_imputer.fit_transform(train_df[mean_col])\n",
        "train_df[mode_col]=mode_imputer.fit_transform(train_df[mode_col])\n",
        "\n",
        "test_df[mean_col]= mean_imputer.transform(test_df[mean_col])\n",
        "test_df[mode_col]= mode_imputer.transform(test_df[mode_col])\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-23T16:29:36.133458Z",
          "iopub.execute_input": "2025-07-23T16:29:36.133787Z",
          "iopub.status.idle": "2025-07-23T16:29:37.180227Z",
          "shell.execute_reply.started": "2025-07-23T16:29:36.13376Z",
          "shell.execute_reply": "2025-07-23T16:29:37.179403Z"
        },
        "id": "P3_4DCp_oy5o"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.isnull().sum()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-23T16:29:37.18118Z",
          "iopub.execute_input": "2025-07-23T16:29:37.181581Z",
          "iopub.status.idle": "2025-07-23T16:29:37.210156Z",
          "shell.execute_reply.started": "2025-07-23T16:29:37.181555Z",
          "shell.execute_reply": "2025-07-23T16:29:37.209417Z"
        },
        "id": "O9QqSq_roy5o"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Criteria 4\n",
        "## Identify and handle duplicates"
      ],
      "metadata": {
        "id": "V1uyjec8oy5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.drop(\"id\", axis=1, inplace=True)\n",
        "train_df = train_df[train_df.duplicated()==False]\n",
        "train_df.reset_index(inplace=True, drop=True)\n",
        "print(\"Duplicates:\", train_df.duplicated().sum())\n",
        "#No duplicates"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-23T16:29:37.211174Z",
          "iopub.execute_input": "2025-07-23T16:29:37.212039Z",
          "iopub.status.idle": "2025-07-23T16:29:37.345547Z",
          "shell.execute_reply.started": "2025-07-23T16:29:37.212015Z",
          "shell.execute_reply": "2025-07-23T16:29:37.344623Z"
        },
        "id": "1lNC_-21oy5p"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Criteria 5\n",
        "## Identify and handle outliers"
      ],
      "metadata": {
        "id": "7RiOTLwqoy5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "numerical_cols = ['credit_score','age','tenure','estimated_salary','acc_balance']\n",
        "\n",
        "plt.figure(figsize=(15, 20))\n",
        "for i, col in enumerate(numerical_cols, 1):\n",
        "    plt.subplot(len(numerical_cols), 1, i)\n",
        "    sns.boxplot(x=train_df[col])\n",
        "    plt.title(f'Boxplot for {col}')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-23T16:29:37.346543Z",
          "iopub.execute_input": "2025-07-23T16:29:37.346869Z",
          "iopub.status.idle": "2025-07-23T16:29:38.649152Z",
          "shell.execute_reply.started": "2025-07-23T16:29:37.34684Z",
          "shell.execute_reply": "2025-07-23T16:29:38.648128Z"
        },
        "id": "HCeurCz1oy5p"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Keeping the outliers\n",
        "* credit_score\n",
        "    \n",
        "      1. Lower outliers below ~400.\n",
        "      2. A low credit score is not an error — it's a valid and important indicator of financial risk.\n",
        "      3. Customers with poor credit might be more likely to exit or churn — this pattern could help the model.\n",
        "* age\n",
        "\n",
        "      1. Outliers above ~60–90 years.\n",
        "      2. Senior customers may behave differently in retention\n",
        "      3. Age extremes are informative, not noise."
      ],
      "metadata": {
        "id": "fFbzemW5oy5q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Criteria 6\n",
        "## Present at least three visualizations and provide insights for the same"
      ],
      "metadata": {
        "id": "G-BMtlzcoy5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exit rate by country\n",
        "sns.countplot(x='country', hue='exit_status', data=train_df)\n",
        "plt.title('Churn Rate by Country')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-23T16:29:38.650279Z",
          "iopub.execute_input": "2025-07-23T16:29:38.650712Z",
          "iopub.status.idle": "2025-07-23T16:29:38.873565Z",
          "shell.execute_reply.started": "2025-07-23T16:29:38.650687Z",
          "shell.execute_reply": "2025-07-23T16:29:38.872722Z"
        },
        "id": "RoHJaScWoy5r"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Observation\n",
        "* France has the largest number of customers, but a lower proportion of churners compared to its total customer base.\n",
        "\n",
        "* Germany has a relatively high churn rate, as the number of churned customers (exit_status = 1) is closer in proportion to those who stayed.\n",
        "\n",
        "* Spain has moderate churn counts but lower than France and Germany overall."
      ],
      "metadata": {
        "id": "e4R0wVDjoy5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Age distribution for churned customers\n",
        "sns.histplot(train_df[train_df['exit_status'] == 1]['age'], bins=30, kde=True)\n",
        "plt.title(\"Age Distribution of Exiting Customers\")\n",
        "plt.xlabel(\"Age\")\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-23T16:29:38.874462Z",
          "iopub.execute_input": "2025-07-23T16:29:38.874754Z",
          "iopub.status.idle": "2025-07-23T16:29:39.310226Z",
          "shell.execute_reply.started": "2025-07-23T16:29:38.874727Z",
          "shell.execute_reply": "2025-07-23T16:29:39.30938Z"
        },
        "id": "eolcChJsoy5r"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Observation\n",
        "* The churn rate peaks around age 45 — this age group has the highest number of exits.\n",
        "\n",
        "* The distribution is right-skewed, indicating fewer churners among older customers (age 60+).\n",
        "\n",
        "* Very young customers (under 30) also churn less frequently than middle-aged ones.\n",
        "\n",
        "* Middle-aged customers (35–50 years old) are the most likely to churn, based on this distribution.\n",
        "This group likely has more financial products, responsibilities, or service expectations making them more sensitive to dissatisfaction."
      ],
      "metadata": {
        "id": "SKCCkpudoy5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Credit Score by Exit Status\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.histplot(data=train_df, x='credit_score', hue='exit_status', bins=30, kde=True, palette='Set1', alpha=0.6)\n",
        "plt.title(\"Credit Score Distribution: Exited vs Stayed\")\n",
        "plt.xlabel(\"Credit Score\")\n",
        "plt.ylabel(\"Customer Count\")\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-23T16:29:39.311209Z",
          "iopub.execute_input": "2025-07-23T16:29:39.311484Z",
          "iopub.status.idle": "2025-07-23T16:29:40.092697Z",
          "shell.execute_reply.started": "2025-07-23T16:29:39.311463Z",
          "shell.execute_reply": "2025-07-23T16:29:40.091665Z"
        },
        "id": "NrFQ95BKoy5s"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Observation\n",
        "1. Stayed customers (exit_status = 0):\n",
        "    * Have a wide distribution centered around scores of 650–700.\n",
        "    * Count drops off after 750 and below 600.\n",
        "2. Exited customers (exit_status = 1):\n",
        "    * Also concentrated in the 600–700 range, but with fewer customers across all score   bands.\n",
        "    * Interestingly, many churned customers also have decent credit scores, meaning good credit alone doesn't guarantee retention."
      ],
      "metadata": {
        "id": "dru7BvXGoy5s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Criteria 7\n",
        "## Scale Numerical features and Encode Categorical features"
      ],
      "metadata": {
        "id": "HVov8kh1oy5s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "num_cols = ['credit_score', 'age', 'tenure', 'acc_balance', 'prod_count', 'estimated_salary']\n",
        "cat_cols = ['country', 'gender', 'has_card', 'is_active']\n",
        "\n",
        "tree_preprocessor = ColumnTransformer([\n",
        "    ('num', 'passthrough', num_cols),\n",
        "    ('cat', OneHotEncoder(handle_unknown='ignore', drop='if_binary'), cat_cols)\n",
        "])\n",
        "\n",
        "mlp_preprocessor = ColumnTransformer([\n",
        "    ('num', StandardScaler(), num_cols),\n",
        "    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)\n",
        "])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-23T16:29:40.096818Z",
          "iopub.execute_input": "2025-07-23T16:29:40.097704Z",
          "iopub.status.idle": "2025-07-23T16:29:40.104309Z",
          "shell.execute_reply.started": "2025-07-23T16:29:40.09767Z",
          "shell.execute_reply": "2025-07-23T16:29:40.103391Z"
        },
        "id": "mx9kDFmyoy5s"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reasoning for scaling numerical features\n",
        "Numerical features like credit_score, age, tenure, etc., vary in scale — some are in hundreds (like credit_score), while others are in single digits (like tenure or prod_count). This variation can negatively impact models that:\n",
        "* Are sensitive to feature scale (e.g., Logistic Regression, SVM, KNN, SGD, Neural Networks).\n",
        "\n",
        "Scaling ensures that all features contribute equally to the learning process and prevents dominance of high-magnitude features.\n",
        "\n",
        "## Reason for choosing StandardScaler\n",
        "StandardScaler standardizes features by removing the mean and scaling to unit variance (i.e., it transforms the distribution to have mean = 0 and standard deviation = 1).\n",
        "We chose StandardScaler because it works well with most models that assume or benefit from normalized inputs.\n",
        "\n",
        "## Reason for encoding categorical features\n",
        "Machine learning models can’t interpret textual or categorical variables directly. These need to be converted into numeric values. If left unencoded, models like logistic regression or tree ensembles can’t use them effectively.\n",
        "\n",
        "## Reason for choosing OneHotEncoder\n",
        "OneHotEncoder creates a new binary column for each category. This is the safest and most general encoding method for nominal (unordered) categorical variables. It works best for non-ordinal categorical variables, and it avoids misleading numerical ordering."
      ],
      "metadata": {
        "id": "h_7Qbpjroy5t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Criteria 8\n",
        "## Model Building (at least 7)"
      ],
      "metadata": {
        "id": "s4UM4sH4oy5t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-23T16:29:40.105257Z",
          "iopub.execute_input": "2025-07-23T16:29:40.10558Z",
          "iopub.status.idle": "2025-07-23T16:29:44.878492Z",
          "shell.execute_reply.started": "2025-07-23T16:29:40.10555Z",
          "shell.execute_reply": "2025-07-23T16:29:44.877619Z"
        },
        "id": "g7vcaQl2oy5u"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import f1_score, roc_auc_score\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "\n",
        "X = train_df.drop('exit_status', axis=1)\n",
        "y = train_df['exit_status']\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=500, class_weight='balanced',random_state=42),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(class_weight='balanced',random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(class_weight='balanced',random_state=42),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
        "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss',\n",
        "                              scale_pos_weight=(y == 0).sum() / (y == 1).sum(),random_state=42),\n",
        "    \"KNN\": KNeighborsClassifier(),\n",
        "    \"Neural Net\": MLPClassifier(max_iter=300, early_stopping=True),\n",
        "    \"AdaBoost\": AdaBoostClassifier(n_estimators=100,random_state=42),\n",
        "    \"SGDClassifier\": SGDClassifier(loss='log_loss', max_iter=1000, random_state=42, class_weight='balanced')\n",
        "}\n",
        "\n",
        "scaled_models = [\n",
        "    \"Logistic Regression\", \"KNN\", \"Neural Net\", \"SGDClassifier\"\n",
        "]\n",
        "\n",
        "print(\"Model Performance on Validation Set:\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "for name, model in models.items():\n",
        "    preprocessor = mlp_preprocessor if name in scaled_models else tree_preprocessor\n",
        "\n",
        "    pipeline = Pipeline([\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', model)\n",
        "    ])\n",
        "\n",
        "    pipeline.fit(X_train, y_train)\n",
        "    y_pred = pipeline.predict(X_val)\n",
        "    y_prob = pipeline.predict_proba(X_val)[:, 1] if hasattr(pipeline.named_steps['classifier'], 'predict_proba') else None\n",
        "\n",
        "    f1 = f1_score(y_val, y_pred)\n",
        "    roc_auc = roc_auc_score(y_val, y_prob) if y_prob is not None else \"N/A\"\n",
        "\n",
        "    print(f\"{name:<20} | F1 Score: {f1:.4f} | ROC AUC: {roc_auc if roc_auc=='N/A' else round(roc_auc, 4)}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-23T16:29:44.879641Z",
          "iopub.execute_input": "2025-07-23T16:29:44.879947Z",
          "iopub.status.idle": "2025-07-23T16:30:33.345223Z",
          "shell.execute_reply.started": "2025-07-23T16:29:44.879919Z",
          "shell.execute_reply": "2025-07-23T16:30:33.34429Z"
        },
        "id": "p-rUeVINoy5u"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "num_cols = ['credit_score', 'age', 'tenure', 'acc_balance', 'prod_count', 'estimated_salary']\n",
        "cat_cols = ['country', 'gender', 'has_card', 'is_active']\n",
        "\n",
        "tree_preprocessor = ColumnTransformer([\n",
        "    ('num', 'passthrough', num_cols),\n",
        "    ('cat', OneHotEncoder(handle_unknown='ignore', drop='if_binary'), cat_cols)\n",
        "])\n",
        "\n",
        "mlp_preprocessor = ColumnTransformer([\n",
        "    ('num', StandardScaler(), num_cols),\n",
        "    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)\n",
        "])\n",
        "\n",
        "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss',\n",
        "                    scale_pos_weight=(y == 0).sum() / (y == 1).sum(), random_state=42)\n",
        "gb = GradientBoostingClassifier(random_state=42)\n",
        "mlp = MLPClassifier(max_iter=300, early_stopping=True, random_state=42)\n",
        "\n",
        "xgb_pipe = Pipeline([\n",
        "    ('preprocessor', tree_preprocessor),\n",
        "    ('classifier', xgb)\n",
        "])\n",
        "\n",
        "gb_pipe = Pipeline([\n",
        "    ('preprocessor', tree_preprocessor),\n",
        "    ('classifier', gb)\n",
        "])\n",
        "\n",
        "mlp_pipe = Pipeline([\n",
        "    ('preprocessor', mlp_preprocessor),\n",
        "    ('classifier', mlp)\n",
        "])\n",
        "\n",
        "\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('xgb', xgb_pipe),\n",
        "        ('gb', gb_pipe),\n",
        "        ('mlp', mlp_pipe),\n",
        "    ],\n",
        "    voting='soft'\n",
        ")\n",
        "\n",
        "voting_clf.fit(X_train, y_train)\n",
        "y_pred_vote = voting_clf.predict(X_val)\n",
        "y_prob_vote = voting_clf.predict_proba(X_val)[:, 1]\n",
        "\n",
        "f1_vote = f1_score(y_val, y_pred_vote)\n",
        "roc_auc_vote = roc_auc_score(y_val, y_prob_vote)\n",
        "\n",
        "print(f\"VotingClassifier        | F1 Score: {f1_vote:.4f} | ROC AUC: {roc_auc_vote:.4f}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-23T16:30:33.346214Z",
          "iopub.execute_input": "2025-07-23T16:30:33.347033Z",
          "iopub.status.idle": "2025-07-23T16:30:52.643392Z",
          "shell.execute_reply.started": "2025-07-23T16:30:33.347006Z",
          "shell.execute_reply": "2025-07-23T16:30:52.642528Z"
        },
        "id": "TH4vYZ90oy5u"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Criteria 9\n",
        "## Hyperparameter Tuning on any 3 of the models"
      ],
      "metadata": {
        "id": "4n1Zu61moy5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold, RandomizedSearchCV\n",
        "from scipy.stats import randint, uniform\n",
        "from sklearn.pipeline import Pipeline\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-23T16:30:52.644303Z",
          "iopub.execute_input": "2025-07-23T16:30:52.644571Z",
          "iopub.status.idle": "2025-07-23T16:30:52.649867Z",
          "shell.execute_reply.started": "2025-07-23T16:30:52.64455Z",
          "shell.execute_reply": "2025-07-23T16:30:52.649037Z"
        },
        "id": "8JWqttBuoy5v"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_pipe = Pipeline([\n",
        "    ('preprocessor', mlp_preprocessor),\n",
        "    ('classifier', MLPClassifier(max_iter=1000, early_stopping=True, random_state=42))\n",
        "])\n",
        "\n",
        "mlp_param_dist = {\n",
        "    'classifier__hidden_layer_sizes': [(100,), (100, 50), (150, 100), (128, 64)],\n",
        "    'classifier__activation': ['relu', 'tanh'],\n",
        "    'classifier__alpha': uniform(0.0001, 0.01),\n",
        "    'classifier__learning_rate_init': uniform(0.001, 0.009),\n",
        "    'classifier__solver': ['adam', 'sgd'],\n",
        "    'classifier__batch_size': [64, 128, 'auto']\n",
        "}\n",
        "\n",
        "mlp_search = RandomizedSearchCV(\n",
        "    mlp_pipe,\n",
        "    mlp_param_dist,\n",
        "    scoring='f1',\n",
        "    cv=cv,\n",
        "    n_iter=30,\n",
        "    verbose=1,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-23T16:30:52.650719Z",
          "iopub.execute_input": "2025-07-23T16:30:52.65103Z",
          "iopub.status.idle": "2025-07-23T16:30:52.671818Z",
          "shell.execute_reply.started": "2025-07-23T16:30:52.651004Z",
          "shell.execute_reply": "2025-07-23T16:30:52.670872Z"
        },
        "id": "8SuoPxH3oy5w"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_pipe = Pipeline([\n",
        "    ('preprocessor', tree_preprocessor),\n",
        "    ('classifier', XGBClassifier(use_label_encoder=False, eval_metric='logloss',\n",
        "                                 scale_pos_weight=(y == 0).sum() / (y == 1).sum(),\n",
        "                                 random_state=42))\n",
        "])\n",
        "\n",
        "xgb_param_dist = {\n",
        "    'classifier__n_estimators': randint(100, 300),\n",
        "    'classifier__learning_rate': uniform(0.01, 0.2),\n",
        "    'classifier__max_depth': randint(3, 10),\n",
        "    'classifier__subsample': uniform(0.7, 0.3),\n",
        "    'classifier__colsample_bytree': uniform(0.6, 0.4),\n",
        "    'classifier__gamma': uniform(0, 0.3),\n",
        "    'classifier__reg_alpha': uniform(0, 0.2),\n",
        "    'classifier__reg_lambda': uniform(0.5, 1.5)\n",
        "}\n",
        "\n",
        "xgb_search = RandomizedSearchCV(\n",
        "    xgb_pipe,\n",
        "    xgb_param_dist,\n",
        "    scoring='f1',\n",
        "    cv=cv,\n",
        "    n_iter=30,\n",
        "    verbose=1,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-23T16:30:52.672916Z",
          "iopub.execute_input": "2025-07-23T16:30:52.673284Z",
          "iopub.status.idle": "2025-07-23T16:30:52.702424Z",
          "shell.execute_reply.started": "2025-07-23T16:30:52.673257Z",
          "shell.execute_reply": "2025-07-23T16:30:52.701384Z"
        },
        "id": "s5cWyOhooy5w"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "gb_pipe = Pipeline([\n",
        "    ('preprocessor', tree_preprocessor),\n",
        "    ('classifier', GradientBoostingClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "gb_param_dist = {\n",
        "    'classifier__n_estimators': randint(100, 250),\n",
        "    'classifier__learning_rate': uniform(0.01, 0.2),\n",
        "    'classifier__max_depth': randint(3, 10),\n",
        "    'classifier__subsample': uniform(0.7, 0.3),\n",
        "    'classifier__min_samples_split': randint(2, 10),\n",
        "    'classifier__min_samples_leaf': randint(1, 5),\n",
        "    'classifier__max_features': ['sqrt', 'log2', None]\n",
        "}\n",
        "\n",
        "gb_search = RandomizedSearchCV(\n",
        "    gb_pipe,\n",
        "    gb_param_dist,\n",
        "    scoring='f1',\n",
        "    cv=cv,\n",
        "    n_iter=30,\n",
        "    verbose=1,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-23T16:30:52.703806Z",
          "iopub.execute_input": "2025-07-23T16:30:52.704129Z",
          "iopub.status.idle": "2025-07-23T16:30:52.715421Z",
          "shell.execute_reply.started": "2025-07-23T16:30:52.704106Z",
          "shell.execute_reply": "2025-07-23T16:30:52.714373Z"
        },
        "id": "R27_P7Ceoy5w"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_search.fit(X_train, y_train)\n",
        "print(\"\\nBest XGB F1 Score:\", xgb_search.best_score_)\n",
        "print(\"Best XGB Params:\", xgb_search.best_params_)\n",
        "\n",
        "gb_search.fit(X_train, y_train)\n",
        "print(\"\\nBest Gradient Boost F1 Score:\", gb_search.best_score_)\n",
        "print(\"Best GB Params:\", gb_search.best_params_)\n",
        "\n",
        "mlp_search.fit(X_train, y_train)\n",
        "print(\"\\nBest MLP F1 Score:\", mlp_search.best_score_)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-23T16:30:52.71631Z",
          "iopub.execute_input": "2025-07-23T16:30:52.716608Z",
          "iopub.status.idle": "2025-07-23T17:00:01.794716Z",
          "shell.execute_reply.started": "2025-07-23T16:30:52.71658Z",
          "shell.execute_reply": "2025-07-23T17:00:01.793858Z"
        },
        "id": "gBW-3gkfoy6B"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking tuned models on Validation set"
      ],
      "metadata": {
        "id": "SZ3YEatSoy6B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, roc_auc_score\n",
        "\n",
        "xgb_tuned = xgb_search.best_estimator_\n",
        "gb_tuned = gb_search.best_estimator_\n",
        "mlp_tuned = mlp_search.best_estimator_\n",
        "\n",
        "\n",
        "for name, model in zip(['XGBoost', 'Gradient Boosting', 'MLP'], [xgb_tuned, gb_tuned, mlp_tuned]):\n",
        "    y_pred = model.predict(X_val)\n",
        "    y_prob = model.predict_proba(X_val)[:, 1]\n",
        "\n",
        "    f1 = f1_score(y_val, y_pred)\n",
        "    roc_auc = roc_auc_score(y_val, y_prob)\n",
        "\n",
        "    print(f\"{name} (Tuned) - F1 Score: {f1:.4f}, ROC AUC: {roc_auc:.4f}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-23T17:00:01.795688Z",
          "iopub.execute_input": "2025-07-23T17:00:01.795972Z",
          "iopub.status.idle": "2025-07-23T17:00:02.174892Z",
          "shell.execute_reply.started": "2025-07-23T17:00:01.795944Z",
          "shell.execute_reply": "2025-07-23T17:00:02.173942Z"
        },
        "id": "C9g6870Eoy6C"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trying voting classifier on tuned models"
      ],
      "metadata": {
        "id": "Fv5edqXvoy6C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import f1_score, roc_auc_score\n",
        "\n",
        "xgbVC_pipe = Pipeline([\n",
        "    ('preprocessor', tree_preprocessor),\n",
        "    ('classifier', xgb_search.best_estimator_.named_steps['classifier'])\n",
        "])\n",
        "\n",
        "gbVC_pipe = Pipeline([\n",
        "    ('preprocessor', tree_preprocessor),\n",
        "    ('classifier', gb_search.best_estimator_.named_steps['classifier'])\n",
        "])\n",
        "\n",
        "mlpVC_pipe = Pipeline([\n",
        "    ('preprocessor', mlp_preprocessor),\n",
        "    ('classifier', mlp_search.best_estimator_.named_steps['classifier'])\n",
        "])\n",
        "\n",
        "\n",
        "voting_clf_tuned = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('xgb', xgbVC_pipe),\n",
        "        ('gb', gbVC_pipe),\n",
        "        ('mlp', mlpVC_pipe),\n",
        "    ],\n",
        "    voting='soft',\n",
        "    weights=[6, 5, 4]\n",
        ")\n",
        "\n",
        "voting_clf_tuned.fit(X_train, y_train)\n",
        "y_prob_vote = voting_clf_tuned.predict_proba(X_val)[:, 1]\n",
        "y_pred_vote = (y_prob_vote >= 0.40).astype(int)\n",
        "\n",
        "f1_vote = f1_score(y_val, y_pred_vote)\n",
        "roc_auc_vote = roc_auc_score(y_val, y_prob_vote)\n",
        "\n",
        "print(\"VotingClassifier (Tuned Models + Separate Preprocessing)\")\n",
        "print(f\"F1 Score : {f1_vote:.4f}\")\n",
        "print(f\"ROC AUC  : {roc_auc_vote:.4f}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-23T17:00:02.175906Z",
          "iopub.execute_input": "2025-07-23T17:00:02.176253Z",
          "iopub.status.idle": "2025-07-23T17:00:43.393986Z",
          "shell.execute_reply.started": "2025-07-23T17:00:02.176225Z",
          "shell.execute_reply": "2025-07-23T17:00:43.393067Z"
        },
        "id": "b8HGpit3oy6C"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "VotingClassifier (Tuned Models + Separate Preprocessing)\n",
        "F1 Score : 0.6425\n",
        "ROC AUC  : 0.8791"
      ],
      "metadata": {
        "id": "Ua02Lcfgoy6C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "voting_probs = voting_clf_tuned.predict_proba(X_val)[:, 1]\n",
        "\n",
        "best_thresh_vote = 0.5\n",
        "best_f1_vote = 0\n",
        "\n",
        "for thresh in np.arange(0.3, 0.7, 0.01):\n",
        "    preds = (voting_probs >= thresh).astype(int)\n",
        "    score = f1_score(y_val, preds)\n",
        "    if score > best_f1_vote:\n",
        "        best_f1_vote = score\n",
        "        best_thresh_vote = thresh\n",
        "\n",
        "print(f\"[Voting] Best Threshold: {best_thresh_vote:.2f}, Best F1 Score: {best_f1_vote:.4f}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-23T17:00:43.39492Z",
          "iopub.execute_input": "2025-07-23T17:00:43.395225Z",
          "iopub.status.idle": "2025-07-23T17:00:43.841649Z",
          "shell.execute_reply.started": "2025-07-23T17:00:43.395197Z",
          "shell.execute_reply": "2025-07-23T17:00:43.840838Z"
        },
        "id": "GUf-qM2joy6D"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best Threshold: 0.45, Best F1 Score: 0.6463\n"
      ],
      "metadata": {
        "id": "xEuxiB6Aoy6D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Criteria 10\n",
        "## Comparison of model performances"
      ],
      "metadata": {
        "id": "6CKODUhJoy6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "validation_f1_scores = {\n",
        "    'Logistic Regression': 0.5460,\n",
        "    'Decision Tree': 0.5102,\n",
        "    'Random Forest': 0.5921,\n",
        "    'Gradient Boosting': 0.6051,\n",
        "    'XGBoost': 0.6243,\n",
        "    'KNN': 0.5778,\n",
        "    'Neural Net (MLP)': 0.5968,\n",
        "    'AdaBoost': 0.5993,\n",
        "    'SGDClassifier': 0.5374,\n",
        "    'VotingClassifier': 0.6349,\n",
        "\n",
        "    'XGBoost (Tuned)': 0.6305,\n",
        "    'Gradient Boosting (Tuned)': 0.6102,\n",
        "    'MLPClassifier (Tuned)': 0.6010,\n",
        "    'VotingClassifier (Tuned)': 0.6463,\n",
        "}\n",
        "\n",
        "f1_comparison_df = pd.DataFrame.from_dict(validation_f1_scores, orient='index', columns=['F1 Score'])\n",
        "f1_comparison_df = f1_comparison_df.sort_values(by='F1 Score', ascending=False)\n",
        "\n",
        "print(\"F1 Score Comparison Across Models (Validation Set Only):\")\n",
        "print(f1_comparison_df)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-23T17:00:43.842632Z",
          "iopub.execute_input": "2025-07-23T17:00:43.842931Z",
          "iopub.status.idle": "2025-07-23T17:00:43.852449Z",
          "shell.execute_reply.started": "2025-07-23T17:00:43.842903Z",
          "shell.execute_reply": "2025-07-23T17:00:43.851753Z"
        },
        "id": "4sY3Y4rkoy6D"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "test_probs = voting_clf_tuned.predict_proba(test_df)[:, 1]\n",
        "test_preds = (test_probs >= 0.45).astype(int)  # Use best threshold\n",
        "\n",
        "submission_df = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'exit_status': test_preds\n",
        "})\n",
        "\n",
        "submission_df.to_csv('submission.csv', index=False)\n",
        "print(\"Submission file created using threshold 0.40 and tuned ensemble.\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-23T17:00:43.853394Z",
          "iopub.execute_input": "2025-07-23T17:00:43.853701Z",
          "iopub.status.idle": "2025-07-23T17:00:44.1631Z",
          "shell.execute_reply.started": "2025-07-23T17:00:43.853673Z",
          "shell.execute_reply": "2025-07-23T17:00:44.162276Z"
        },
        "id": "UY9gcFO1oy6E"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}